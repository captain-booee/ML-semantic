{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOW.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlfd8zUEDajI"
      },
      "source": [
        "import ast\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import recall_score,precision_score\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.preprocessing import MaxAbsScaler \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "with open(\"drive/MyDrive/ml data/sets/data/train_count.csv\", \"r\") as lines:\n",
        "  for i in lines.readlines()[1:]:\n",
        "    train_features = i.strip().split(\",\",2)\n",
        "    y_train.append(train_features[0])\n",
        "    x_train.append(dict(ast.literal_eval(train_features[2].replace('\"',''))))\n",
        "\n",
        "x_dev = []\n",
        "y_dev = []\n",
        "\n",
        "with open(\"drive/MyDrive/ml data/sets/data/dev_count.csv\", \"r\") as lines:\n",
        "  for i in lines.readlines()[1:]:\n",
        "    dev_features = i.strip().split(\",\",2)\n",
        "    y_dev.append(dev_features[0])\n",
        "    x_dev.append(dict(ast.literal_eval(dev_features[2].replace('\"',''))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX1ItnnrDuNH"
      },
      "source": [
        "vec = DictVectorizer()\n",
        "x_vectorized = vec.fit_transform(x_train)\n",
        "x_dev_vectorized = vec.transform(x_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMNcFNkRFFiJ"
      },
      "source": [
        "scaler = MaxAbsScaler() \n",
        "scaler.fit(x_vectorized)  \n",
        "X_train = scaler.transform(x_vectorized) \n",
        "X_dev = scaler.transform(x_dev_vectorized) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQWxPnvRD1JD"
      },
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(x_vectorized, y_train)\n",
        "y_pred_class = nb.predict(x_dev_vectorized)\n",
        "#print(metrics.accuracy_score(y_dev, y_pred_class))\n",
        "print(metrics.confusion_matrix(y_dev, y_pred_class,labels=[\"pos\", \"neg\", \"neu\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkk3o-RrD7dt"
      },
      "source": [
        "clf = LogisticRegression(solver='newton-cg').fit(x_vectorized, y_train)\n",
        "y_pred_class_logistic = clf.predict(x_dev_vectorized)\n",
        "print(metrics.confusion_matrix(y_dev, y_pred_class_logistic,labels=[\"pos\", \"neg\", \"neu\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7nfMo-kE33N"
      },
      "source": [
        "model = Perceptron(eta0=0.9,max_iter=1500).fit(x_vectorized, y_train)\n",
        "#its faster than logistic R\n",
        "y_pred_class_perceptron = model.predict(x_dev_vectorized)\n",
        "print(metrics.confusion_matrix(y_dev, y_pred_class_perceptron,labels=[\"pos\", \"neg\", \"neu\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnaHaFDdFD4I"
      },
      "source": [
        "mlp = MLPClassifier(alpha=0.10,max_iter=600,solver='adam',hidden_layer_sizes=(3),activation='relu').fit(x_vectorized, y_train)\n",
        "y_pred_class_mlp = mlp.predict(x_dev_vectorized)\n",
        "print(metrics.confusion_matrix(y_dev, y_pred_class_mlp,labels=[\"pos\", \"neg\", \"neu\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHNdTMwsFS__"
      },
      "source": [
        "from sklearn.svm import SVC  \n",
        "svc_l = SVC(kernel='poly',shrinking=False) \n",
        "#0.713553702401286 poly\n",
        "#0.7009444388626545 sigmoid\n",
        "svc_l.fit(x_vectorized, y_train) \n",
        "y_pred_class_mlp = svc_l.predict(x_dev_vectorized)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}